reading dataset
{'loss': 2.9843, 'learning_rate': 4.9500000000000004e-05, 'epoch': 1.0}
{'loss': 2.7017, 'learning_rate': 4.9e-05, 'epoch': 2.0}
{'loss': 2.5934, 'learning_rate': 4.85e-05, 'epoch': 3.0}
{'loss': 2.5249, 'learning_rate': 4.8e-05, 'epoch': 4.0}
{'loss': 2.4725, 'learning_rate': 4.75e-05, 'epoch': 5.0}
{'loss': 2.4306, 'learning_rate': 4.7e-05, 'epoch': 6.0}
{'loss': 2.3969, 'learning_rate': 4.6500000000000005e-05, 'epoch': 7.0}
{'loss': 2.367, 'learning_rate': 4.600000000000001e-05, 'epoch': 8.0}
{'loss': 2.339, 'learning_rate': 4.55e-05, 'epoch': 9.0}
{'loss': 2.3158, 'learning_rate': 4.5e-05, 'epoch': 10.0}
{'loss': 2.2936, 'learning_rate': 4.4500000000000004e-05, 'epoch': 11.0}
{'loss': 2.2745, 'learning_rate': 4.4000000000000006e-05, 'epoch': 12.0}
{'loss': 2.2574, 'learning_rate': 4.35e-05, 'epoch': 13.0}
{'loss': 2.2405, 'learning_rate': 4.3e-05, 'epoch': 14.0}
{'loss': 2.2249, 'learning_rate': 4.25e-05, 'epoch': 15.0}
{'loss': 2.2102, 'learning_rate': 4.2e-05, 'epoch': 16.0}
{'loss': 2.1978, 'learning_rate': 4.15e-05, 'epoch': 17.0}
{'loss': 2.1844, 'learning_rate': 4.1e-05, 'epoch': 18.0}
{'loss': 2.1738, 'learning_rate': 4.05e-05, 'epoch': 19.0}
{'loss': 2.1625, 'learning_rate': 4e-05, 'epoch': 20.0}
{'loss': 2.1525, 'learning_rate': 3.9500000000000005e-05, 'epoch': 21.0}
{'loss': 2.1424, 'learning_rate': 3.9000000000000006e-05, 'epoch': 22.0}
{'loss': 2.1328, 'learning_rate': 3.85e-05, 'epoch': 23.0}
{'loss': 2.1235, 'learning_rate': 3.8e-05, 'epoch': 24.0}
{'loss': 2.1149, 'learning_rate': 3.7500000000000003e-05, 'epoch': 25.0}
{'loss': 2.1063, 'learning_rate': 3.7e-05, 'epoch': 26.0}
{'loss': 2.0996, 'learning_rate': 3.65e-05, 'epoch': 27.0}
{'loss': 2.091, 'learning_rate': 3.6e-05, 'epoch': 28.0}
{'loss': 2.0829, 'learning_rate': 3.55e-05, 'epoch': 29.0}
{'loss': 2.0774, 'learning_rate': 3.5e-05, 'epoch': 30.0}
{'loss': 2.0708, 'learning_rate': 3.45e-05, 'epoch': 31.0}
{'loss': 2.0639, 'learning_rate': 3.4000000000000007e-05, 'epoch': 32.0}
{'loss': 2.0585, 'learning_rate': 3.35e-05, 'epoch': 33.0}
{'loss': 2.0513, 'learning_rate': 3.3e-05, 'epoch': 34.0}
{'loss': 2.0452, 'learning_rate': 3.2500000000000004e-05, 'epoch': 35.0}
{'loss': 2.0408, 'learning_rate': 3.2000000000000005e-05, 'epoch': 36.0}
{'loss': 2.0357, 'learning_rate': 3.15e-05, 'epoch': 37.0}
{'loss': 2.031, 'learning_rate': 3.1e-05, 'epoch': 38.0}
{'loss': 2.0242, 'learning_rate': 3.05e-05, 'epoch': 39.0}
{'loss': 2.0194, 'learning_rate': 3e-05, 'epoch': 40.0}
{'loss': 2.0164, 'learning_rate': 2.95e-05, 'epoch': 41.0}
{'loss': 2.0104, 'learning_rate': 2.9e-05, 'epoch': 42.0}
{'loss': 2.0063, 'learning_rate': 2.8499999999999998e-05, 'epoch': 43.0}
{'loss': 2.0027, 'learning_rate': 2.8000000000000003e-05, 'epoch': 44.0}
{'loss': 1.998, 'learning_rate': 2.7500000000000004e-05, 'epoch': 45.0}
{'loss': 1.9935, 'learning_rate': 2.7000000000000002e-05, 'epoch': 46.0}
{'loss': 1.9899, 'learning_rate': 2.6500000000000004e-05, 'epoch': 47.0}
{'loss': 1.9864, 'learning_rate': 2.6000000000000002e-05, 'epoch': 48.0}
{'loss': 1.9822, 'learning_rate': 2.5500000000000003e-05, 'epoch': 49.0}
{'loss': 1.9788, 'learning_rate': 2.5e-05, 'epoch': 50.0}
{'loss': 1.9749, 'learning_rate': 2.45e-05, 'epoch': 51.0}
{'loss': 1.972, 'learning_rate': 2.4e-05, 'epoch': 52.0}
{'loss': 1.9703, 'learning_rate': 2.35e-05, 'epoch': 53.0}
{'loss': 1.9664, 'learning_rate': 2.3000000000000003e-05, 'epoch': 54.0}
{'loss': 1.9629, 'learning_rate': 2.25e-05, 'epoch': 55.0}
{'loss': 1.9592, 'learning_rate': 2.2000000000000003e-05, 'epoch': 56.0}
{'loss': 1.9557, 'learning_rate': 2.15e-05, 'epoch': 57.0}
{'loss': 1.9542, 'learning_rate': 2.1e-05, 'epoch': 58.0}
{'loss': 1.952, 'learning_rate': 2.05e-05, 'epoch': 59.0}
{'loss': 1.9494, 'learning_rate': 2e-05, 'epoch': 60.0}
{'loss': 1.9467, 'learning_rate': 1.9500000000000003e-05, 'epoch': 61.0}
{'loss': 1.9441, 'learning_rate': 1.9e-05, 'epoch': 62.0}
{'loss': 1.9409, 'learning_rate': 1.85e-05, 'epoch': 63.0}
{'loss': 1.9406, 'learning_rate': 1.8e-05, 'epoch': 64.0}
{'loss': 1.9374, 'learning_rate': 1.75e-05, 'epoch': 65.0}
{'loss': 1.935, 'learning_rate': 1.7000000000000003e-05, 'epoch': 66.0}
{'loss': 1.9329, 'learning_rate': 1.65e-05, 'epoch': 67.0}
{'loss': 1.9311, 'learning_rate': 1.6000000000000003e-05, 'epoch': 68.0}
{'loss': 1.929, 'learning_rate': 1.55e-05, 'epoch': 69.0}
{'loss': 1.9266, 'learning_rate': 1.5e-05, 'epoch': 70.0}
{'loss': 1.9245, 'learning_rate': 1.45e-05, 'epoch': 71.0}
{'loss': 1.9226, 'learning_rate': 1.4000000000000001e-05, 'epoch': 72.0}
{'loss': 1.9216, 'learning_rate': 1.3500000000000001e-05, 'epoch': 73.0}
{'loss': 1.92, 'learning_rate': 1.3000000000000001e-05, 'epoch': 74.0}
{'loss': 1.9186, 'learning_rate': 1.25e-05, 'epoch': 75.0}
{'loss': 1.9167, 'learning_rate': 1.2e-05, 'epoch': 76.0}
{'loss': 1.9151, 'learning_rate': 1.1500000000000002e-05, 'epoch': 77.0}
{'loss': 1.9135, 'learning_rate': 1.1000000000000001e-05, 'epoch': 78.0}
{'loss': 1.9119, 'learning_rate': 1.05e-05, 'epoch': 79.0}
{'loss': 1.9108, 'learning_rate': 1e-05, 'epoch': 80.0}
{'loss': 1.9103, 'learning_rate': 9.5e-06, 'epoch': 81.0}
{'loss': 1.9098, 'learning_rate': 9e-06, 'epoch': 82.0}
{'loss': 1.9079, 'learning_rate': 8.500000000000002e-06, 'epoch': 83.0}
{'loss': 1.9063, 'learning_rate': 8.000000000000001e-06, 'epoch': 84.0}
{'loss': 1.9048, 'learning_rate': 7.5e-06, 'epoch': 85.0}
{'loss': 1.9052, 'learning_rate': 7.000000000000001e-06, 'epoch': 86.0}
{'loss': 1.9044, 'learning_rate': 6.5000000000000004e-06, 'epoch': 87.0}
{'loss': 1.9026, 'learning_rate': 6e-06, 'epoch': 88.0}
{'loss': 1.9022, 'learning_rate': 5.500000000000001e-06, 'epoch': 89.0}
{'loss': 1.9011, 'learning_rate': 5e-06, 'epoch': 90.0}
{'loss': 1.9002, 'learning_rate': 4.5e-06, 'epoch': 91.0}
{'loss': 1.9001, 'learning_rate': 4.000000000000001e-06, 'epoch': 92.0}
{'loss': 1.9004, 'learning_rate': 3.5000000000000004e-06, 'epoch': 93.0}
{'loss': 1.8993, 'learning_rate': 3e-06, 'epoch': 94.0}
{'loss': 1.8985, 'learning_rate': 2.5e-06, 'epoch': 95.0}
{'loss': 1.8975, 'learning_rate': 2.0000000000000003e-06, 'epoch': 96.0}
{'loss': 1.8982, 'learning_rate': 1.5e-06, 'epoch': 97.0}
{'loss': 1.8978, 'learning_rate': 1.0000000000000002e-06, 'epoch': 98.0}
{'loss': 1.8985, 'learning_rate': 5.000000000000001e-07, 'epoch': 99.0}
{'loss': 1.8972, 'learning_rate': 0.0, 'epoch': 100.0}
{'train_runtime': 7567.5291, 'train_samples_per_second': 188.793, 'train_steps_per_second': 11.8, 'train_loss': 2.0507333992576813, 'epoch': 100.0}
***** train metrics *****
  epoch                    =      100.0
  train_loss               =     2.0507
  train_runtime            = 2:06:07.52
  train_samples            =      14287
  train_samples_per_second =    188.793
  train_steps_per_second   =       11.8
