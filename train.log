reading dataset
Dataset({
    features: ['input_ids', 'attention_mask', 'labels'],
    num_rows: 1472
})
{'loss': 3.4328, 'learning_rate': 4.9500000000000004e-05, 'epoch': 1.0}
{'loss': 2.9746, 'learning_rate': 4.9e-05, 'epoch': 2.0}
{'loss': 2.8107, 'learning_rate': 4.85e-05, 'epoch': 3.0}
{'loss': 2.7176, 'learning_rate': 4.8e-05, 'epoch': 4.0}
{'loss': 2.6463, 'learning_rate': 4.75e-05, 'epoch': 5.0}
{'loss': 2.5862, 'learning_rate': 4.7e-05, 'epoch': 6.0}
{'loss': 2.539, 'learning_rate': 4.6500000000000005e-05, 'epoch': 7.0}
{'loss': 2.4979, 'learning_rate': 4.600000000000001e-05, 'epoch': 8.0}
{'loss': 2.464, 'learning_rate': 4.55e-05, 'epoch': 9.0}
{'loss': 2.4348, 'learning_rate': 4.5e-05, 'epoch': 10.0}
{'loss': 2.4066, 'learning_rate': 4.4500000000000004e-05, 'epoch': 11.0}
{'loss': 2.3847, 'learning_rate': 4.4000000000000006e-05, 'epoch': 12.0}
{'loss': 2.3631, 'learning_rate': 4.35e-05, 'epoch': 13.0}
{'loss': 2.3377, 'learning_rate': 4.3e-05, 'epoch': 14.0}
{'loss': 2.3184, 'learning_rate': 4.25e-05, 'epoch': 15.0}
{'loss': 2.297, 'learning_rate': 4.2e-05, 'epoch': 16.0}
{'loss': 2.2855, 'learning_rate': 4.15e-05, 'epoch': 17.0}
{'loss': 2.269, 'learning_rate': 4.1e-05, 'epoch': 18.0}
{'loss': 2.2506, 'learning_rate': 4.05e-05, 'epoch': 19.0}
{'loss': 2.2394, 'learning_rate': 4e-05, 'epoch': 20.0}
{'loss': 2.2264, 'learning_rate': 3.9500000000000005e-05, 'epoch': 21.0}
{'loss': 2.2142, 'learning_rate': 3.9000000000000006e-05, 'epoch': 22.0}
{'loss': 2.2041, 'learning_rate': 3.85e-05, 'epoch': 23.0}
{'loss': 2.1918, 'learning_rate': 3.8e-05, 'epoch': 24.0}
{'loss': 2.1819, 'learning_rate': 3.7500000000000003e-05, 'epoch': 25.0}
{'loss': 2.1702, 'learning_rate': 3.7e-05, 'epoch': 26.0}
{'loss': 2.1619, 'learning_rate': 3.65e-05, 'epoch': 27.0}
{'loss': 2.1521, 'learning_rate': 3.6e-05, 'epoch': 28.0}
{'loss': 2.1422, 'learning_rate': 3.55e-05, 'epoch': 29.0}
{'loss': 2.1362, 'learning_rate': 3.5e-05, 'epoch': 30.0}
{'loss': 2.129, 'learning_rate': 3.45e-05, 'epoch': 31.0}
{'loss': 2.1207, 'learning_rate': 3.4000000000000007e-05, 'epoch': 32.0}
{'loss': 2.1117, 'learning_rate': 3.35e-05, 'epoch': 33.0}
{'loss': 2.104, 'learning_rate': 3.3e-05, 'epoch': 34.0}
{'loss': 2.0957, 'learning_rate': 3.2500000000000004e-05, 'epoch': 35.0}
{'loss': 2.0912, 'learning_rate': 3.2000000000000005e-05, 'epoch': 36.0}
{'loss': 2.0847, 'learning_rate': 3.15e-05, 'epoch': 37.0}
{'loss': 2.0785, 'learning_rate': 3.1e-05, 'epoch': 38.0}
{'loss': 2.0735, 'learning_rate': 3.05e-05, 'epoch': 39.0}
{'loss': 2.069, 'learning_rate': 3e-05, 'epoch': 40.0}
{'loss': 2.0638, 'learning_rate': 2.95e-05, 'epoch': 41.0}
{'loss': 2.0574, 'learning_rate': 2.9e-05, 'epoch': 42.0}
{'loss': 2.0512, 'learning_rate': 2.8499999999999998e-05, 'epoch': 43.0}
{'loss': 2.0459, 'learning_rate': 2.8000000000000003e-05, 'epoch': 44.0}
{'loss': 2.0435, 'learning_rate': 2.7500000000000004e-05, 'epoch': 45.0}
{'loss': 2.0349, 'learning_rate': 2.7000000000000002e-05, 'epoch': 46.0}
{'loss': 2.0354, 'learning_rate': 2.6500000000000004e-05, 'epoch': 47.0}
{'loss': 2.0314, 'learning_rate': 2.6000000000000002e-05, 'epoch': 48.0}
{'loss': 2.0227, 'learning_rate': 2.5500000000000003e-05, 'epoch': 49.0}
{'loss': 2.0185, 'learning_rate': 2.5e-05, 'epoch': 50.0}
{'loss': 2.0124, 'learning_rate': 2.45e-05, 'epoch': 51.0}
{'loss': 2.0138, 'learning_rate': 2.4e-05, 'epoch': 52.0}
{'loss': 2.0077, 'learning_rate': 2.35e-05, 'epoch': 53.0}
{'loss': 2.003, 'learning_rate': 2.3000000000000003e-05, 'epoch': 54.0}
{'loss': 2.0015, 'learning_rate': 2.25e-05, 'epoch': 55.0}
{'loss': 1.9986, 'learning_rate': 2.2000000000000003e-05, 'epoch': 56.0}
{'loss': 1.9905, 'learning_rate': 2.15e-05, 'epoch': 57.0}
{'loss': 1.9923, 'learning_rate': 2.1e-05, 'epoch': 58.0}
{'loss': 1.9879, 'learning_rate': 2.05e-05, 'epoch': 59.0}
{'loss': 1.9843, 'learning_rate': 2e-05, 'epoch': 60.0}
{'loss': 1.9812, 'learning_rate': 1.9500000000000003e-05, 'epoch': 61.0}
{'loss': 1.9764, 'learning_rate': 1.9e-05, 'epoch': 62.0}
{'loss': 1.9803, 'learning_rate': 1.85e-05, 'epoch': 63.0}
{'loss': 1.9713, 'learning_rate': 1.8e-05, 'epoch': 64.0}
{'loss': 1.9737, 'learning_rate': 1.75e-05, 'epoch': 65.0}
{'loss': 1.9661, 'learning_rate': 1.7000000000000003e-05, 'epoch': 66.0}
{'loss': 1.9655, 'learning_rate': 1.65e-05, 'epoch': 67.0}
{'loss': 1.9653, 'learning_rate': 1.6000000000000003e-05, 'epoch': 68.0}
{'loss': 1.9597, 'learning_rate': 1.55e-05, 'epoch': 69.0}
{'loss': 1.9628, 'learning_rate': 1.5e-05, 'epoch': 70.0}
{'loss': 1.9584, 'learning_rate': 1.45e-05, 'epoch': 71.0}
{'loss': 1.9565, 'learning_rate': 1.4000000000000001e-05, 'epoch': 72.0}
{'loss': 1.9519, 'learning_rate': 1.3500000000000001e-05, 'epoch': 73.0}
{'loss': 1.9499, 'learning_rate': 1.3000000000000001e-05, 'epoch': 74.0}
{'loss': 1.9476, 'learning_rate': 1.25e-05, 'epoch': 75.0}
{'loss': 1.9463, 'learning_rate': 1.2e-05, 'epoch': 76.0}
{'loss': 1.9451, 'learning_rate': 1.1500000000000002e-05, 'epoch': 77.0}
{'loss': 1.9433, 'learning_rate': 1.1000000000000001e-05, 'epoch': 78.0}
{'loss': 1.943, 'learning_rate': 1.05e-05, 'epoch': 79.0}
{'loss': 1.9399, 'learning_rate': 1e-05, 'epoch': 80.0}
{'loss': 1.9367, 'learning_rate': 9.5e-06, 'epoch': 81.0}
{'loss': 1.9374, 'learning_rate': 9e-06, 'epoch': 82.0}
{'loss': 1.9359, 'learning_rate': 8.500000000000002e-06, 'epoch': 83.0}
{'loss': 1.9361, 'learning_rate': 8.000000000000001e-06, 'epoch': 84.0}
{'loss': 1.9349, 'learning_rate': 7.5e-06, 'epoch': 85.0}
{'loss': 1.9384, 'learning_rate': 7.000000000000001e-06, 'epoch': 86.0}
{'loss': 1.9363, 'learning_rate': 6.5000000000000004e-06, 'epoch': 87.0}
{'loss': 1.9321, 'learning_rate': 6e-06, 'epoch': 88.0}
{'loss': 1.9307, 'learning_rate': 5.500000000000001e-06, 'epoch': 89.0}
{'loss': 1.929, 'learning_rate': 5e-06, 'epoch': 90.0}
{'loss': 1.9274, 'learning_rate': 4.5e-06, 'epoch': 91.0}
{'loss': 1.9287, 'learning_rate': 4.000000000000001e-06, 'epoch': 92.0}
{'loss': 1.9289, 'learning_rate': 3.5000000000000004e-06, 'epoch': 93.0}
{'loss': 1.9283, 'learning_rate': 3e-06, 'epoch': 94.0}
{'loss': 1.9293, 'learning_rate': 2.5e-06, 'epoch': 95.0}
{'loss': 1.9305, 'learning_rate': 2.0000000000000003e-06, 'epoch': 96.0}
{'loss': 1.9267, 'learning_rate': 1.5e-06, 'epoch': 97.0}
{'loss': 1.9288, 'learning_rate': 1.0000000000000002e-06, 'epoch': 98.0}
{'loss': 1.9257, 'learning_rate': 5.000000000000001e-07, 'epoch': 99.0}
{'loss': 1.9259, 'learning_rate': 0.0, 'epoch': 100.0}
{'train_runtime': 791.5881, 'train_samples_per_second': 185.955, 'train_steps_per_second': 11.622, 'train_loss': 2.1120319266941237, 'epoch': 100.0}
***** train metrics *****
  epoch                    =      100.0
  train_loss               =      2.112
  train_runtime            = 0:13:11.58
  train_samples            =       1472
  train_samples_per_second =    185.955
  train_steps_per_second   =     11.622
